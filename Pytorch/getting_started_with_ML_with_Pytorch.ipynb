{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88508aba",
   "metadata": {},
   "source": [
    "Machine Learning with Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e3be4a",
   "metadata": {},
   "source": [
    "PyTorch is an open source framework for AI research and commercial production in machine learning. It is used to build, train and optmize deep learning neural networks for applications such as image recognition, natural language processing, and speech recognition. It provides computation support for CPU, GPU, parallel and distributed training on multiple GPUs and multiple nodes. PyTorch is also flexible and easily extensible, with specific libraries and tools available for many different domains. All of the above have made PyTorch a leading framework in machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8ed789",
   "metadata": {},
   "source": [
    "This lab shows you how easy is to get started with PyTorch and use it to build, train and evaluate a neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da34b16c",
   "metadata": {},
   "source": [
    "Objectives\n",
    "\n",
    "After completing this lab you will be able to:\n",
    "\n",
    "    - Install necessary PyTorch libraries;\n",
    "    - Use PyTorch to build, train and evaluate neural networks.\n",
    "    - Save the trained model parameters and use them later for inferencing.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e84ab1",
   "metadata": {},
   "source": [
    "Setup\n",
    "\n",
    "For this lab, we will be using the following libraries:\n",
    "\n",
    "    - torch\n",
    "    - TorchVision   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1713610",
   "metadata": {},
   "source": [
    "Importing Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af60faad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "853ab661",
   "metadata": {},
   "source": [
    "How does this lab work?\n",
    "\n",
    "The lab uses MNIST datasets. The dataset has over 60,000 images of hand written digits. The data will be partitioned between training the AI model and testing the AI model after training.\n",
    "\n",
    "The main steps in this project include:\n",
    "\n",
    "1. Download the MNIST dataset and create a DataLoader for the dataset.\n",
    "2. Define an AI model to recognize a hand written digit.\n",
    "3. Train the defined AI model using training data from the MNIST dataset.\n",
    "4. Test the trained AI model using testing data from the MNIST dataset.\n",
    "5. Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d4eed6e",
   "metadata": {},
   "source": [
    "Download Dataset and Create Data Loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8a9a78",
   "metadata": {},
   "source": [
    "The images are 28x28 pixel images of digits 0 through 9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "56f61cc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data size 60032\n",
      "Test data size: 10048\n",
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y: torch.Size([64]) torch.int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:3: SyntaxWarning: invalid escape sequence '\\P'\n",
      "<>:11: SyntaxWarning: invalid escape sequence '\\P'\n",
      "<>:3: SyntaxWarning: invalid escape sequence '\\P'\n",
      "<>:11: SyntaxWarning: invalid escape sequence '\\P'\n",
      "C:\\Users\\Anthonny\\AppData\\Local\\Temp\\ipykernel_2832\\2042593826.py:3: SyntaxWarning: invalid escape sequence '\\P'\n",
      "  root=\"..\\Pytorch\\Datasets\",\n",
      "C:\\Users\\Anthonny\\AppData\\Local\\Temp\\ipykernel_2832\\2042593826.py:11: SyntaxWarning: invalid escape sequence '\\P'\n",
      "  root=\"..\\Pytorch\\Datasets\",\n"
     ]
    }
   ],
   "source": [
    "# Download training data from the MNIST datasets.\n",
    "training_data = datasets.MNIST(\n",
    "    root=\"..\\Pytorch\\Datasets\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "# Download test data from open datasets.\n",
    "test_data = datasets.MNIST(\n",
    "    root=\"..\\Pytorch\\Datasets\",\n",
    "    train=False, \n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "# Create data loaders to iterate over data\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "print(\"Training data size\", len(train_dataloader) * batch_size)\n",
    "print(\"Test data size:\", len(test_dataloader) * batch_size)\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
    "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e61cc66f",
   "metadata": {},
   "source": [
    "Define Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96aae9b8",
   "metadata": {},
   "source": [
    "We first determine the best device for perfoming training with cpu as the default device.\n",
    "\n",
    "We then define the AI model as a neural network with 3 layers: an input layer, a hidden layer, and an output layer.\n",
    "Between the layers, we use ReLU activation function.\n",
    "\n",
    "Since the input images are 1x28x28 tensors, we need to flatten the input tensors into a 784 element tensor using the Flatten module before passing the input into our neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0bc4da8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "# Get device for training.\n",
    "device = torch.device(\n",
    "    \"cuda\" if torch.cuda.is_available()\n",
    "    else \"mps\" if torch.backends.mps.is_available() # Apple Silicon GPU\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "#Define model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, image_tensor):\n",
    "        image_tensor = self.flatten(image_tensor)\n",
    "        logits = self.linear_relu_stack(image_tensor)\n",
    "        return logits\n",
    "    \n",
    "input_size = 28*28\n",
    "hidden_size = 512\n",
    "num_classes = 10\n",
    "\n",
    "model = NeuralNetwork(input_size, hidden_size, num_classes).to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ec3fa2",
   "metadata": {},
   "source": [
    "Trainin Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690d76db",
   "metadata": {},
   "source": [
    "We implement a training function to use with the train_dataloader to train our model. Each iteration over the dataloader returns a batch_size image data tensor along with the expected output. After moving the tensor to the device, we call the forward pass of our model, compute the predicition error using the expected output and then call the backwards pass to compute the gradients and apply them to the model parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9839b342",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our learning rate, loss function and optimizer\n",
    "learning_rate = 1e-3 #0.001\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Let's define our training function\n",
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "\n",
    "    for batch_num, (X, y) in enumerate(dataloader):\n",
    "        X,y = X.to(device), y.to(device)\n",
    "\n",
    "        # Forward pass to compute prediction\n",
    "        pred = model(X)\n",
    "        # Compute prediction error using loss function\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backward pass\n",
    "        optimizer.zero_grad() # zero any previous gradient calculations\n",
    "        loss.backward() # calculate gradient\n",
    "        optimizer.step() # update model parameters\n",
    "\n",
    "        if batch_num > 0 and batch_num % 100 == 0:\n",
    "            loss, current = loss.item(), batch_num * len(X)\n",
    "            print(f\"loss : {loss:>7f}   [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcaaa450",
   "metadata": {},
   "source": [
    "Test Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9541e05f",
   "metadata": {},
   "source": [
    "The test methods evaluates the model's predictive perfomance using the test_dataloader. During testing, we don't require gradient computation, so we set the model in evaluate mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c1848923",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our test function\n",
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    for X, y in dataloader:\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        pred = model(X)\n",
    "        test_loss += loss_fn(pred, y).item()\n",
    "        correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "        test_loss /= num_batches\n",
    "        correct /= size\n",
    "        print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee19014",
   "metadata": {},
   "source": [
    "Train the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50c8e75",
   "metadata": {},
   "source": [
    "Now that we have defined methods to train our model and test the trained model's predictive behavior, lets train the model for 5 epochs over the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "57bbeae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-----------------------\n",
      "loss : 0.259129   [ 6400/60000]\n",
      "loss : 0.193589   [12800/60000]\n",
      "loss : 0.252482   [19200/60000]\n",
      "loss : 0.128381   [25600/60000]\n",
      "loss : 0.296876   [32000/60000]\n",
      "loss : 0.131317   [38400/60000]\n",
      "loss : 0.241594   [44800/60000]\n",
      "loss : 0.252764   [51200/60000]\n",
      "loss : 0.188765   [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000208 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000215 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000342 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000886 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001046 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001469 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000861 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001113 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000643 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001032 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001343 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001133 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000702 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001133 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001541 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000952 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001290 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000699 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.002528 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.003398 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001763 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000686 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001201 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.002293 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001317 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001259 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001857 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001103 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001175 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001655 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001208 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001981 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.002349 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.002096 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001302 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001872 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000389 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.002935 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001373 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000806 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001455 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.002135 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001184 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000765 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000884 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001535 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001684 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000843 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001153 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000302 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001147 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000483 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001137 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000138 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001269 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.002431 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001128 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001279 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001858 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.002735 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001475 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001609 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.002163 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001946 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.002472 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001281 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001305 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001404 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001073 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001105 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.002065 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001242 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001701 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000813 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000508 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.002154 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001586 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.002488 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000503 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000118 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000574 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000184 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000062 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000417 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000071 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000492 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000380 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000798 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001461 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001056 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000018 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000853 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000473 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000966 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001871 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000106 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000553 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000023 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000010 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000210 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000098 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000460 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001681 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001748 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000133 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000609 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000593 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000086 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000263 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000032 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000179 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000084 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000364 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000300 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000022 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000051 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000724 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000370 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000095 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000323 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000641 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000033 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000217 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000938 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000049 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000985 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000876 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000308 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000308 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000963 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000800 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000441 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000244 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000457 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000428 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000015 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000020 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000157 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000026 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000344 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001335 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000843 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000357 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000598 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000073 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001317 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000362 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000060 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000208 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001065 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001164 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001426 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.002159 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001993 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001278 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001390 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.2%, Avg loss: 0.000188 \n",
      "\n",
      "Epoch 2\n",
      "-----------------------\n",
      "loss : 0.068538   [ 6400/60000]\n",
      "loss : 0.128836   [12800/60000]\n",
      "loss : 0.065410   [19200/60000]\n",
      "loss : 0.079495   [25600/60000]\n",
      "loss : 0.118456   [32000/60000]\n",
      "loss : 0.043047   [38400/60000]\n",
      "loss : 0.138810   [44800/60000]\n",
      "loss : 0.162442   [51200/60000]\n",
      "loss : 0.103539   [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000068 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000143 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000245 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001125 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000502 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000831 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000517 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000993 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000169 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000565 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000648 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000466 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000168 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000764 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001193 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000901 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000622 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000656 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.002421 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.002887 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000912 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000290 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000390 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001877 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001088 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001131 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001577 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000828 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000319 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001131 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000809 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001506 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001761 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001582 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000623 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001338 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000212 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001645 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000883 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000436 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001233 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.002242 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000855 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000301 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000463 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001845 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001458 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000719 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000781 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000114 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000488 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000109 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000594 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000218 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001112 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.002197 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000400 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000624 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000887 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001910 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000893 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001103 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001314 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000970 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000795 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000652 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000827 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001005 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000502 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000460 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001818 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000732 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001343 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000417 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000359 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001795 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000777 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001077 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000282 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000049 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000168 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000186 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000016 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000390 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000010 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000158 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000046 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000855 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001256 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000906 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000010 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000461 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000518 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001113 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001805 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000461 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001132 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000008 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000003 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000033 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000031 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000397 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001091 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001521 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000065 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000163 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000145 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000010 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000079 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000007 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000028 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000021 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000157 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000526 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000040 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000071 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000465 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000054 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000022 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000121 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000181 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000008 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000187 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000431 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000014 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000545 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000275 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000076 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000519 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001781 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000715 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000373 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000168 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000719 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000059 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000026 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000003 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000075 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000004 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000047 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001162 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000569 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000029 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000219 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000015 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001283 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000314 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000014 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000032 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001039 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000388 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000942 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001965 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000674 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000410 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000652 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.2%, Avg loss: 0.000064 \n",
      "\n",
      "Epoch 3\n",
      "-----------------------\n",
      "loss : 0.058443   [ 6400/60000]\n",
      "loss : 0.057828   [12800/60000]\n",
      "loss : 0.112533   [19200/60000]\n",
      "loss : 0.045329   [25600/60000]\n",
      "loss : 0.086266   [32000/60000]\n",
      "loss : 0.034571   [38400/60000]\n",
      "loss : 0.088099   [44800/60000]\n",
      "loss : 0.074200   [51200/60000]\n",
      "loss : 0.054527   [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000117 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000376 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000163 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001458 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000377 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001177 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000838 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001440 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000177 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000750 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000792 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000384 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000076 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000950 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001528 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000854 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000544 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001172 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.002849 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.003059 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001200 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000292 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000544 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.002460 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001464 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001282 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.002304 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000793 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000649 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001191 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000984 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001413 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001594 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001452 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000227 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000956 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000393 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001519 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001062 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000552 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000946 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.002002 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001045 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000463 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000397 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001866 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001441 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001105 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000744 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000158 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000340 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000142 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000335 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000440 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001428 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.003918 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000234 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000517 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000433 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001669 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000333 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001683 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001280 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000761 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001188 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000700 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001089 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001331 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000516 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000716 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.002590 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000805 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001897 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000216 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000703 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.002000 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001062 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000940 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000348 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000029 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000127 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000084 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000010 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000546 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000010 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000152 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000078 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000948 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001444 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000958 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000007 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000118 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000575 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001545 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.002803 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000619 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001156 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000008 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000002 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000022 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000010 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000239 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001053 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.002215 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000033 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000336 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000049 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000005 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000011 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000006 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000024 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000036 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000113 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000350 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000048 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000021 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000388 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000026 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000030 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000319 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000792 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000011 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000303 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000248 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000007 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000235 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000515 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000028 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000841 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.003410 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000794 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000697 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000377 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000763 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000128 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000041 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000007 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000020 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000003 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000054 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001582 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000691 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000127 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000668 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000021 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001908 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000661 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000020 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000010 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001008 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000442 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000714 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001854 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000912 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000220 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000644 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.2%, Avg loss: 0.000026 \n",
      "\n",
      "Epoch 4\n",
      "-----------------------\n",
      "loss : 0.012315   [ 6400/60000]\n",
      "loss : 0.041731   [12800/60000]\n",
      "loss : 0.159680   [19200/60000]\n",
      "loss : 0.046286   [25600/60000]\n",
      "loss : 0.020964   [32000/60000]\n",
      "loss : 0.012645   [38400/60000]\n",
      "loss : 0.071836   [44800/60000]\n",
      "loss : 0.104790   [51200/60000]\n",
      "loss : 0.023645   [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000023 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000473 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000105 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001561 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000209 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000387 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000982 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001069 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000137 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001020 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000336 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000521 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000094 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000642 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001683 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000983 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000432 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001142 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001305 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.002675 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000802 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000086 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000270 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001629 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001237 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001309 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001645 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000523 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000331 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001456 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001061 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001510 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000767 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001220 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000058 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001191 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000097 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001068 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000789 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000189 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000560 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001509 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000670 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000590 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000372 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.002817 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000494 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000373 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000629 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000226 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000574 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000189 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000239 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000963 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000565 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.003333 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000231 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000684 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000957 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.002372 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000266 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001731 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000203 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001041 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000866 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000731 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000822 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000849 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000075 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000176 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.002014 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000356 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001959 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000149 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000234 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.002511 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000855 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000786 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000385 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000113 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000251 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000169 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000003 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000308 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000035 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000205 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000138 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000511 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001809 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000759 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000005 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000082 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000465 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001189 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001548 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000031 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000468 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000003 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000001 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000009 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000002 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000257 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000988 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001909 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000032 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000476 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000014 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000006 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000014 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000006 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000008 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000021 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000157 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000415 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000018 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000024 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000379 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000021 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000007 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000002 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000118 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000007 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000609 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000373 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000009 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000026 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000210 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000018 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000756 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001129 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000875 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000285 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000022 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000368 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000042 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000005 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000001 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000006 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000001 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000032 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.002450 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001112 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000012 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000148 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000011 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001320 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000269 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000005 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000002 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000769 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000287 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000944 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001867 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000941 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000295 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000380 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.2%, Avg loss: 0.000013 \n",
      "\n",
      "Epoch 5\n",
      "-----------------------\n",
      "loss : 0.024111   [ 6400/60000]\n",
      "loss : 0.078307   [12800/60000]\n",
      "loss : 0.034584   [19200/60000]\n",
      "loss : 0.018654   [25600/60000]\n",
      "loss : 0.024874   [32000/60000]\n",
      "loss : 0.012767   [38400/60000]\n",
      "loss : 0.012046   [44800/60000]\n",
      "loss : 0.082227   [51200/60000]\n",
      "loss : 0.035221   [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000004 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000321 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000125 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001549 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000377 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000679 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001184 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000342 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000097 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001414 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000597 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000529 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000069 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000503 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001171 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001010 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000473 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001446 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001073 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.002857 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000948 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000650 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000513 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001328 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001560 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000753 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001265 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000748 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000186 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001389 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000701 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001114 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000749 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001054 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000023 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001167 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000029 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001031 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000416 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000374 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000749 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001488 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000972 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000314 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000449 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.002919 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000170 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000599 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000586 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000245 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000844 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000373 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000618 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000553 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000638 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.003220 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000214 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000065 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000473 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001475 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000199 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001387 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000619 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001217 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001211 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000683 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000424 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000718 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000148 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000152 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001986 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000056 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000760 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000110 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000283 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.002140 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000651 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000605 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000526 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000047 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000150 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000089 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000007 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000496 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000057 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000133 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000054 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000051 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.002020 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000674 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000006 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000529 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000926 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000487 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000413 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000005 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000024 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000000 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000000 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000018 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000007 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000005 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001755 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001352 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000108 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000527 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000091 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000002 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000008 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000004 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000064 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000090 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000133 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000079 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000003 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000008 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000434 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000106 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000021 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000001 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000275 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000004 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000963 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000340 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000005 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000037 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000023 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000003 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000299 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000114 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001056 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000211 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000099 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000540 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000005 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000001 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000000 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000001 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000000 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000001 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001225 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000483 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000023 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000122 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000004 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000825 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000282 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000119 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000008 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000870 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000109 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000843 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001768 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.001093 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000294 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.6%, Avg loss: 0.000579 \n",
      "\n",
      "Test Error: \n",
      " Accuracy: 0.2%, Avg loss: 0.000004 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Let's run training\n",
    "epochs = 5\n",
    "for t in range(epochs):\n",
    "    print(f'Epoch {t+1}\\n-----------------------')\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd3ae5a",
   "metadata": {},
   "source": [
    "Save the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87477fc0",
   "metadata": {},
   "source": [
    "Once we have trained a model, we can save the model parameters for future use in inferences. Here we save the state_dict of the model which contains the trained parameters. We then create a new instance of the model and load the previously save parameters into the new instance of the model. Finally we can inference using the new instance of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "87e8aa10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved PyTorch Model State to Pytorch\\models\\ml_with_pytorch_model.pth\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x200 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Salvar os pesos (state_dict) corretamente\n",
    "torch.save(model.state_dict(), \"../Pytorch/models/ml_with_pytorch_model.pth\")\n",
    "print(\"Saved PyTorch Model State to Pytorch\\\\models\\\\ml_with_pytorch_model.pth\")\n",
    "\n",
    "# Recriar a instncia do modelo\n",
    "model = NeuralNetwork(input_size, hidden_size, num_classes).to(device)\n",
    "\n",
    "# Carregar os pesos salvos\n",
    "model.load_state_dict(torch.load(\"../Pytorch/models/ml_with_pytorch_model.pth\", map_location=device))\n",
    "# Usar o modelo para inferncia\n",
    "model.eval()\n",
    "\n",
    "fig, axes = plt.subplots(1, 10, figsize=(15, 2))\n",
    "for i in range(10):\n",
    "    x, y = test_data[i][0], test_data[i][1]\n",
    "\n",
    "    x_input = x.to(device)\n",
    "    pred = model(x_input.unsqueeze(0)) # Adds batch dimension\n",
    "    predicted = pred.argmax(1).item()\n",
    "    \n",
    "    axes[i].imshow(x.squeeze(), cmap='gray')\n",
    "    axes[i].set_title(f'Pred:{predicted}\\nReal:{y}', fontsize=8)\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_pr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
